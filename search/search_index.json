{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"dranspose","text":"<p>dranspose is a framework for distributed live processing.</p>"},{"location":"#applications","title":"Applications","text":"<p>If you are looking for help with developing an application on top of dranspose, have a look at the application section</p>"},{"location":"applications/overview/","title":"Application Development","text":"<p>Unlike sequential processing of data, dranspose leverages parallel processing to achieve the throughput necesary for live processing.</p> <p>We use the map reduce programming model for distributing work. Parallel workers unfortunately have to work independently. Therefore, they only have access  to a single event at a time. They may store local state, but don't have access to arbitrary other events.</p> <p>For data analysis which has to cross all events, there is a secondary reduce step which can only cope with reduced data, but gets all events delivered.</p> <p>A lot of common analysis tasks are easily mapped to this programming model. The map phase perform the heavy lifting, e.g. analysing images and then forwards a spectrum to the reducer which only averages the sprectra or appends them to a list.</p>"},{"location":"applications/overview/#using-dranspose","title":"Using <code>dranspose</code>","text":"<p>Note</p> <p>Before developing a new worker functionality, it is necessary to capture events coming from the streams. Please see capturing events. Here we assume that you have dumps for all necessary streams</p> <p>To analyse data with dranspose, you need to split your task into a <code>map</code> and a <code>redude</code> function.</p> <p>Create a new git repository and create the following structure</p> <pre><code>.\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 src\n    \u251c\u2500\u2500 reducer.py\n    \u2514\u2500\u2500 worker.py\n</code></pre>"},{"location":"applications/overview/#workerpy","title":"<code>worker.py</code>","text":"<p>The worker gets events and has to first parse the messages from the data stream. Then it reduces the data available and forwards a condensed version.</p> <p>The worker class is instantiated for every new trigger map. This allows to use the <code>__init__</code> for resetting the state. All calls provide the current set of <code>parameters</code> which may be required to set the worker up.</p> <p>Creating a logger is useful for development and production.</p> <p><pre><code>import logging\n\nfrom dranspose.event import EventData\nfrom dranspose.middlewares import contrast\nfrom dranspose.middlewares import xspress\n\nlogger = logging.getLogger(__name__)\n\nclass FluorescenceWorker:\n    def __init__(self, parameters=None):\n        self.number = 0\n</code></pre> The <code>process_event</code> function gets an EventData object which contains all required streams for the current event. The first step should be to check that the required streams for the analyis are present. <pre><code>    def process_event(self, event: EventData, parameters=None):\n        logger.debug(\"using parameters %s\", parameters)\n        if {\"contrast\", \"xspress3\"} - set(event.streams.keys()) != set():\n            logger.error(\n                \"missing streams for this worker, only present %s\", event.streams.keys()\n            )\n            return\n</code></pre> Many streams have the same packet structure and therefore <code>dranspose</code> include middlewares to autmatically parse the frames to python objects. <pre><code>        try:\n            con = contrast.parse(event.streams[\"contrast\"])\n        except Exception as e:\n            logger.error(\"failed to parse contrast %s\", e.__repr__())\n            return\n\n        try:\n            spec = xspress.parse(event.streams[\"xspress3\"])\n        except Exception as e:\n            logger.error(\"failed to parse xspress3 %s\", e.__repr__())\n            return\n        logger.error(\"contrast: %s\", con)\n        logger.error(\"spectrum: %s\", spec)\n</code></pre> Check if we are in an event which produces data. Others may be <code>starting</code> or <code>finishing</code> <pre><code>        if con.status == \"running\":\n            # new data\n            sx, sy = con.pseudo[\"x\"][0], con.pseudo[\"y\"][0]\n            logger.error(\"process position %s %s\", sx, sy)\n\n            roi1 = spec.data[3][parameters[\"roi1\"][0] : parameters[\"roi1\"][1]].sum()\n\n            return {\"position\": (sx, sy), \"concentations\": {\"roi1\": roi1}}\n</code></pre></p> <p>The returned object will be available to the reducer</p>"},{"location":"applications/overview/#reducerpy","title":"<code>reducer.py</code>","text":"<p>The reducer may also have a setup in <code>__init__</code> where is may initialise the special <code>publish</code> attribute. This attribute is automatically exposed via http for live viewers</p> <p><pre><code>from dranspose.event import ResultData\n\nclass FluorescenceReducer:\n    def __init__(self, parameters=None):\n        self.number = 0\n        self.publish = {\"map\": {}}\n</code></pre> In <code>process_result</code>, only simple operations are possible, such as appending to a dictionary, as this has to run at the acquisition speed. <pre><code>    def process_result(self, result: ResultData, parameters=None):\n        print(result)\n        if result.payload:\n            self.publish[\"map\"][result.payload[\"position\"]] = result.payload[\n                \"concentations\"\n            ]\n</code></pre></p>"},{"location":"applications/overview/#developing-an-analysis","title":"Developing an analysis","text":"<p>The worker and reducer is easily tested by the <code>dranspose replay</code> command. Provide the worker class <code>-w</code> and the reducer class <code>-r</code>. You also need to provide the dumped stream from each ingester. If you need parameters, you can provide a json or pickle file which will be provided to your worker functions.</p> <pre><code>LOG_LEVEL=\"DEBUG\" dranspose replay -w \"src.worker:FluorescenceWorker\" \\\n    -r \"src.reducer:FluorescenceReducer\" \\\n    -f ../contrast_ingest.pkls ../xspress_ingest.pkls \\\n    -p ../fullparam.json\n</code></pre>"},{"location":"reference/middlewares/","title":"Middlewares","text":"<p>Small helpers to parse the binary frames in the workers.</p>"},{"location":"reference/middlewares/#contrast","title":"Contrast","text":""},{"location":"reference/middlewares/#dranspose.middlewares.contrast.parse","title":"<code>parse(data)</code>","text":"<p>Parses a contrast packet, which returns a dict, depending on the status of contrast</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>StreamData</code> <p>a frame comming from contrast</p> required <p>Returns:</p> Type Description <code>ContrastPacket</code> <p>a ContrastPacket containing a.o. the current status</p> Source code in <code>dranspose/middlewares/contrast.py</code> <pre><code>def parse(data: StreamData) -&gt; ContrastPacket:\n    \"\"\"\n    Parses a contrast packet, which returns a dict, depending on the status of contrast\n\n    Arguments:\n        data: a frame comming from contrast\n\n    Returns:\n        a ContrastPacket containing a.o. the current status\n    \"\"\"\n    assert data.typ == \"contrast\"\n    assert data.length == 1\n    frame = data.frames[0]\n    if isinstance(frame, zmq.Frame):\n        val = pickle.loads(frame.bytes)\n    else:\n        val = pickle.loads(frame)\n\n    return ContrastPacket.validate_python(val)\n</code></pre>"},{"location":"reference/middlewares/#examples","title":"Examples","text":"<pre><code>ContrastStarted(\n    status='started',\n    path='/data/.../diff_1130_stream_test/raw/dummy',\n    scannr=2,\n    description='mesh sx -2 2 3 sy -2 2 4 0.1',\n    snapshot={'attenuator1_x': 0.048, \n              'attenuator2_x': 0.067, \n              'attenuator3_x': 0.536, \n              'vfm_yaw': 0.15148492851039919, \n              'xrf_x': 94.99875}\n)\n</code></pre> <pre><code>ContrastRunning(\n    status='running',\n    dt=2.410903215408325,\n    sx=-2.000431059888797,\n    sy=-2.0011940002441406,\n    pseudo={\n        'x': array([-2.00405186]),\n        'y': array([-2.00290304]),\n        'z': array([0.00029938]),\n        'analog_x': array([-1.99962707]),\n        'analog_y': array([-1.99349905]),\n        'analog_z': array([-0.00306218])\n    },\n    panda0={\n        'COUNTER1.OUT_Value': array([0.]),\n        'COUNTER2.OUT_Value': array([0.]),\n        'COUNTER3.OUT_Value': array([0.]),\n        'FMC_IN.VAL6_Mean': array([0.04644599]),\n        'FMC_IN.VAL7_Mean': array([-0.02943451]),\n        'FMC_IN.VAL8_Mean': array([0.01255371])\n    },\n    xspress3={\n        'type': 'Link',\n        'filename': '/data/.../diff_1130_stream_test/raw/dummy/scan_000002_xspress3.hdf5',\n        'path': '/entry/instrument/xspress3/',\n        'universal': True\n    }\n)\n</code></pre> <pre><code>ContrastFinished(\n    status='finished',\n    path='/data/.../diff_1130_stream_test/raw/dummy',\n    scannr=2,\n    description='mesh sx -2 2 3 sy -2 2 4 0.1',\n    snapshot={'attenuator1_x': 0.048, \n              'attenuator2_x': 0.066, \n              'vfm_yaw': 0.15148492851039919, \n              'xrf_x': 94.99875}\n)\n</code></pre>"},{"location":"reference/middlewares/#xspress3","title":"Xspress3","text":""},{"location":"reference/middlewares/#dranspose.middlewares.xspress.parse","title":"<code>parse(data)</code>","text":"<p>Parses a Xspress3 packet, which either gives a start/end message or a tuple with a spectra array</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>StreamData</code> <p>a frame comming from the Xspress3 tango device</p> required <p>Returns:</p> Type Description <code>XspressPacket</code> <p>an XspressPacket</p> Source code in <code>dranspose/middlewares/xspress.py</code> <pre><code>def parse(\n    data: StreamData,\n) -&gt; XspressPacket:\n    \"\"\"\n    Parses a Xspress3 packet, which either gives a start/end message or a tuple with a spectra array\n\n    Arguments:\n        data: a frame comming from the Xspress3 tango device\n\n    Returns:\n        an XspressPacket\n    \"\"\"\n    assert data.typ == \"xspress\"\n    assert data.length &gt;= 1\n    headerframe = data.frames[0]\n    if isinstance(headerframe, zmq.Frame):\n        headerframe = headerframe.bytes\n    packet = XspressPacket.validate_json(headerframe)\n    print(\"packets\", packet)\n    if isinstance(packet, XspressImage):\n        assert data.length == 3\n        bufframe = data.frames[1]\n        if isinstance(bufframe, zmq.Frame):\n            bufframe = bufframe.bytes\n        buf = np.frombuffer(bufframe, dtype=packet.type)\n        img = buf.reshape(packet.shape)\n        metaframe = data.frames[2]\n        if isinstance(metaframe, zmq.Frame):\n            metaframe = metaframe.bytes\n        meta = pickle.loads(metaframe)\n        # meta description: ocr[0], AllEvents[0], AllGood[0], ClockTicks[0],\n        #                   TotalTicks[0], ResetTicks[0], event_widths, dtc[0]]\n        meta = {\n            k: v\n            for k, v in zip(\n                [\n                    \"ocr\",\n                    \"AllEvents\",\n                    \"AllGood\",\n                    \"ClockTicks\",\n                    \"TotalTicks\",\n                    \"ResetTicks\",\n                    \"event_widths\",\n                    \"dtc\",\n                ],\n                meta,\n            )\n        }\n        packet.data = img\n        packet.meta = meta\n\n    return packet\n</code></pre>"},{"location":"reference/middlewares/#examples_1","title":"Examples","text":"<pre><code>XspressStart(\n    htype='header',\n    filename='/data/.../diff_1130_stream_test/raw/dummy/scan_000002_xspress3.hdf5',\n    overwritable=False\n)\n</code></pre> <p>Note</p> <p>While the original stream sends 3 separate zmq frames (no multipart), this returns a single packet.</p> <pre><code>XspressImage(\n    htype='image',\n    frame=0,\n    shape=[4, 4096],\n    exptime=0.099999875,\n    type='uint32',\n    compression='none',\n    data=array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint32),\n    meta={\n        'ocr': array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.56250195e-15]),\n        'AllEvents': array([2, 0, 0, 3], dtype=uint32),\n        'AllGood': array([0, 0, 0, 1], dtype=uint32),\n        'ClockTicks': array([7999990, 7999990, 7999990, 7999990], dtype=uint32),\n        'TotalTicks': array([7999990, 7999990, 7999990, 7999990], dtype=uint32),\n        'ResetTicks': array([ 0,  0,  0, 91], dtype=uint32),\n        'event_widths': array([6, 6, 6, 6], dtype=int32),\n        'dtc': array([1.00000175, 1.        , 1.        , 1.000014  ])\n    }\n)\n</code></pre> <pre><code>XspressEnd(htype='series_end')\n</code></pre>"},{"location":"reference/trigger_map/","title":"Trigger Map","text":"<p>The trigger map is the core part of dranspose and answers the following question:</p> <p>Question</p> <p>Which frames from which streams belong to the same event and have to be processed by the same worker?</p>"},{"location":"reference/internals/distributed_service/","title":"Distributed service","text":""},{"location":"reference/internals/distributed_service/#dranspose.distributed.DistributedService","title":"<code>DistributedService</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract class defining common functionality for all services.</p> Source code in <code>dranspose/distributed.py</code> <pre><code>class DistributedService(abc.ABC):\n    \"\"\"\n    Abstract class defining common functionality for all services.\n    \"\"\"\n\n    def __init__(\n        self,\n        state: WorkerState | IngesterState | ReducerState,\n        settings: Optional[DistributedSettings] = None,\n    ):\n        self._distributed_settings = settings\n        if self._distributed_settings is None:\n            self._distributed_settings = DistributedSettings()\n\n        self.state: WorkerState | IngesterState | ReducerState = state\n\n        if \":\" in state.name:\n            raise Exception(\"Worker name must not contain a :\")\n        # TODO: check for already existing query string\n        self.redis = redis.from_url(\n            f\"{self._distributed_settings.redis_dsn}?decode_responses=True&amp;protocol=3\"\n        )\n        self.raw_redis = redis.from_url(\n            f\"{self._distributed_settings.redis_dsn}?protocol=3\"\n        )\n        self._logger = logging.getLogger(f\"{__name__}+{self.state.name}\")\n        self.parameters = None\n\n    async def register(self) -&gt; None:\n        \"\"\"\n        Background job in every distributed service to publish the service's configuration.\n        It publishes the `state` every 6 seconds or faster if there are updates from the controller with a new trigger map or parameters.\n        \"\"\"\n        latest = await self.redis.xrevrange(RedisKeys.updates(), count=1)\n        last = 0\n        if len(latest) &gt; 0:\n            last = latest[0][0]\n        while True:\n            if isinstance(self.state, IngesterState):\n                category = \"ingester\"\n            elif isinstance(self.state, WorkerState):\n                category = \"worker\"\n            elif isinstance(self.state, ReducerState):\n                category = \"reducer\"\n            else:\n                raise NotImplemented(\n                    \"Distributed Service not implemented for your Service\"\n                )\n            await self.redis.setex(\n                RedisKeys.config(category, self.state.name),\n                10,\n                self.state.model_dump_json(),\n            )\n            try:\n                update = await self.redis.xread({RedisKeys.updates(): last}, block=6000)\n                if RedisKeys.updates() in update:\n                    update = update[RedisKeys.updates()][0][-1]\n                    last = update[0]\n                    update = ControllerUpdate.model_validate_json(update[1][\"data\"])\n                    self._logger.debug(\"update type %s\", update)\n                    newuuid = update.mapping_uuid\n                    if newuuid != self.state.mapping_uuid:\n                        self._logger.info(\"resetting config to %s\", newuuid)\n                        await self.restart_work(newuuid)\n                    newuuid = update.parameters_uuid\n                    if newuuid != self.state.parameters_uuid:\n                        self._logger.info(\"setting parameters to %s\", newuuid)\n                        try:\n                            params = await self.raw_redis.get(\n                                RedisKeys.parameters(newuuid)\n                            )\n                        except Exception as e:\n                            self._logger.error(\n                                \"failed to get parameters %s\", e.__repr__()\n                            )\n                        self._logger.debug(\"received binary parameters %s\", params)\n                        if params:\n                            self._logger.error(\"set parameters %s\", params)\n                            self.parameters = pickle.loads(params)\n                            self.state.parameters_uuid = newuuid\n                    if update.finished:\n                        self._logger.info(\"finished messages\")\n                        await self.finish_work()\n\n            except rexceptions.ConnectionError:\n                break\n            except asyncio.exceptions.CancelledError:\n                break\n\n    async def restart_work(self, uuid: UUID4) -&gt; None:\n        pass\n\n    async def finish_work(self) -&gt; None:\n        pass\n\n    async def close(self) -&gt; None:\n        await self.redis.aclose()\n        await self.raw_redis.aclose()\n</code></pre>"},{"location":"reference/internals/distributed_service/#dranspose.distributed.DistributedService.register","title":"<code>register()</code>  <code>async</code>","text":"<p>Background job in every distributed service to publish the service's configuration. It publishes the <code>state</code> every 6 seconds or faster if there are updates from the controller with a new trigger map or parameters.</p> Source code in <code>dranspose/distributed.py</code> <pre><code>async def register(self) -&gt; None:\n    \"\"\"\n    Background job in every distributed service to publish the service's configuration.\n    It publishes the `state` every 6 seconds or faster if there are updates from the controller with a new trigger map or parameters.\n    \"\"\"\n    latest = await self.redis.xrevrange(RedisKeys.updates(), count=1)\n    last = 0\n    if len(latest) &gt; 0:\n        last = latest[0][0]\n    while True:\n        if isinstance(self.state, IngesterState):\n            category = \"ingester\"\n        elif isinstance(self.state, WorkerState):\n            category = \"worker\"\n        elif isinstance(self.state, ReducerState):\n            category = \"reducer\"\n        else:\n            raise NotImplemented(\n                \"Distributed Service not implemented for your Service\"\n            )\n        await self.redis.setex(\n            RedisKeys.config(category, self.state.name),\n            10,\n            self.state.model_dump_json(),\n        )\n        try:\n            update = await self.redis.xread({RedisKeys.updates(): last}, block=6000)\n            if RedisKeys.updates() in update:\n                update = update[RedisKeys.updates()][0][-1]\n                last = update[0]\n                update = ControllerUpdate.model_validate_json(update[1][\"data\"])\n                self._logger.debug(\"update type %s\", update)\n                newuuid = update.mapping_uuid\n                if newuuid != self.state.mapping_uuid:\n                    self._logger.info(\"resetting config to %s\", newuuid)\n                    await self.restart_work(newuuid)\n                newuuid = update.parameters_uuid\n                if newuuid != self.state.parameters_uuid:\n                    self._logger.info(\"setting parameters to %s\", newuuid)\n                    try:\n                        params = await self.raw_redis.get(\n                            RedisKeys.parameters(newuuid)\n                        )\n                    except Exception as e:\n                        self._logger.error(\n                            \"failed to get parameters %s\", e.__repr__()\n                        )\n                    self._logger.debug(\"received binary parameters %s\", params)\n                    if params:\n                        self._logger.error(\"set parameters %s\", params)\n                        self.parameters = pickle.loads(params)\n                        self.state.parameters_uuid = newuuid\n                if update.finished:\n                    self._logger.info(\"finished messages\")\n                    await self.finish_work()\n\n        except rexceptions.ConnectionError:\n            break\n        except asyncio.exceptions.CancelledError:\n            break\n</code></pre>"},{"location":"reference/internals/distributed_service/#dranspose.distributed.DistributedSettings","title":"<code>DistributedSettings</code>","text":"<p>             Bases: <code>BaseSettings</code></p> <p>Basic settings for any distributed service</p> <p>Attributes:</p> Name Type Description <code>redis_dsn</code> <code>RedisDsn</code> <p>URL of the common redis instance</p> Source code in <code>dranspose/distributed.py</code> <pre><code>class DistributedSettings(BaseSettings):\n    \"\"\"\n    Basic settings for any distributed service\n\n    Attributes:\n        redis_dsn: URL of the common redis instance\n    \"\"\"\n\n    redis_dsn: RedisDsn = Field(\n        Url(\"redis://localhost:6379/0\"),\n        validation_alias=AliasChoices(\"service_redis_dsn\", \"redis_url\"),\n    )\n</code></pre>"},{"location":"reference/internals/ingester/","title":"Ingester","text":""},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester","title":"<code>Ingester</code>","text":"<p>             Bases: <code>DistributedService</code></p> <p>The Ingester class provides a basis to write custom ingesters for any protocol. It handles all the forwarding to workers and managing assignments. For the instance to do anything, await <code>run()</code></p> Source code in <code>dranspose/ingester.py</code> <pre><code>class Ingester(DistributedService):\n    \"\"\"\n    The Ingester class provides a basis to write custom ingesters for any protocol.\n    It handles all the forwarding to workers and managing assignments.\n    For the instance to do anything, await `run()`\n    \"\"\"\n\n    def __init__(self, name: IngesterName, settings: Optional[IngesterSettings] = None):\n        if settings is None:\n            settings = IngesterSettings()\n        self._ingester_settings = settings\n        streams: list[StreamName] = []\n        state = IngesterState(\n            name=name,\n            url=self._ingester_settings.ingester_url,\n            streams=streams,\n        )\n\n        super().__init__(state=state, settings=self._ingester_settings)\n        self.state: IngesterState\n\n        self.dump_file: Optional[IO[bytes]] = None\n\n        self.ctx = zmq.asyncio.Context()\n        self.out_socket = self.ctx.socket(zmq.ROUTER)\n        self.out_socket.setsockopt(zmq.ROUTER_MANDATORY, 1)\n        self.out_socket.setsockopt(zmq.TCP_KEEPALIVE, 1)\n        self.out_socket.setsockopt(zmq.TCP_KEEPALIVE_IDLE, 300)\n        self.out_socket.setsockopt(zmq.TCP_KEEPALIVE_INTVL, 300)\n        self.out_socket.bind(f\"tcp://*:{self._ingester_settings.ingester_url.port}\")\n\n    async def run(self) -&gt; None:\n        \"\"\"\n        Main function orchestrating the dependent tasks. This needs to be called from an async context once an instance is created.\n        \"\"\"\n        self.accept_task = asyncio.create_task(self.accept_workers())\n        self.work_task = asyncio.create_task(self.work())\n        self.assign_task = asyncio.create_task(self.manage_assignments())\n        self.assignment_queue: asyncio.Queue[WorkAssignment] = asyncio.Queue()\n        await self.register()\n\n    async def restart_work(self, new_uuid: UUID4) -&gt; None:\n        \"\"\"\n        Restarts all work related tasks to make sure no old state is present in a new scan.\n\n        Arguments:\n            new_uuid: The uuid of the new mapping\n        \"\"\"\n        self.work_task.cancel()\n        self.assign_task.cancel()\n        self.state.mapping_uuid = new_uuid\n        self.assignment_queue = asyncio.Queue()\n        self.work_task = asyncio.create_task(self.work())\n        self.assign_task = asyncio.create_task(self.manage_assignments())\n\n    async def finish_work(self) -&gt; None:\n        \"\"\"\n        This hook is called when all events of a trigger map were ingested. It is useful for e.g. closing open files.\n        \"\"\"\n        self._logger.info(\"finishing work\")\n        if self.dump_file:\n            self.dump_file.close()\n            self._logger.info(\"closed dump file at finish %s\", self.dump_file)\n            self.dump_file = None\n\n    async def manage_assignments(self) -&gt; None:\n        \"\"\"\n        A background task reading assignments from the controller, filering them for the relevant ones and enqueueing them for when the frame arrives.\n        \"\"\"\n        self._logger.info(\"started ingester manage assign task\")\n        lastev = 0\n        while True:\n            sub = RedisKeys.assigned(self.state.mapping_uuid)\n            try:\n                assignments = await self.redis.xread({sub: lastev}, block=1000)\n            except rexceptions.ConnectionError:\n                break\n            if sub not in assignments:\n                continue\n            assignment_evs = assignments[sub][0]\n            self._logger.debug(\"got assignments %s\", assignment_evs)\n            for assignment in assignment_evs:\n                wa = WorkAssignment.model_validate_json(assignment[1][\"data\"])\n                mywa = wa.get_workers_for_streams(self.state.streams)\n                await self.assignment_queue.put(mywa)\n                lastev = assignment[0]\n\n    async def work(self) -&gt; None:\n        \"\"\"\n        The heavy liftig function of an ingester. It consumes a generator `run_source()` which\n        should be implemented for a specific protocol.\n        It then assembles all streams for this ingester and forwards them to the assigned workers.\n\n        Optionally the worker dumps the internal messages to disk. This is useful to develop workers with actual data captured.\n        \"\"\"\n        self._logger.info(\"started ingester work task\")\n        sourcegens = {stream: self.run_source(stream) for stream in self.state.streams}\n        self.dump_file = None\n        if self._ingester_settings.dump_path:\n            self.dump_file = open(self._ingester_settings.dump_path, \"ab\")\n            self._logger.info(\n                \"dump file %s opened at %s\",\n                self._ingester_settings.dump_path,\n                self.dump_file,\n            )\n        try:\n            while True:\n                work_assignment: WorkAssignment = await self.assignment_queue.get()\n                workermessages = {}\n                zmqyields: list[Awaitable[StreamData]] = []\n                streams: list[StreamName] = []\n                for stream in work_assignment.assignments:\n                    zmqyields.append(anext(sourcegens[stream]))\n                    streams.append(stream)\n                zmqstreams: list[StreamData] = await asyncio.gather(*zmqyields)\n                zmqparts: dict[StreamName, StreamData] = {\n                    stream: zmqpart for stream, zmqpart in zip(streams, zmqstreams)\n                }\n                if self.dump_file:\n                    self._logger.debug(\n                        \"writing dump to path %s\", self._ingester_settings.dump_path\n                    )\n                    allstr = InternalWorkerMessage(\n                        event_number=work_assignment.event_number,\n                        streams={k: v.get_bytes() for k, v in zmqparts.items()},\n                    )\n                    try:\n                        pickle.dump(allstr, self.dump_file)\n                    except Exception as e:\n                        self._logger.error(\"cound not dump %s\", e.__repr__())\n                    self._logger.debug(\"written dump\")\n                for stream, workers in work_assignment.assignments.items():\n                    for worker in workers:\n                        if worker not in workermessages:\n                            workermessages[worker] = InternalWorkerMessage(\n                                event_number=work_assignment.event_number\n                            )\n                        workermessages[worker].streams[stream] = zmqparts[stream]\n                self._logger.debug(\"workermessages %s\", workermessages)\n                for worker, message in workermessages.items():\n                    self._logger.debug(\n                        \"header is %s\",\n                        message.model_dump_json(\n                            exclude={\"streams\": {\"__all__\": \"frames\"}}\n                        ),\n                    )\n                    await self.out_socket.send_multipart(\n                        [worker.encode(\"ascii\")]\n                        + [\n                            message.model_dump_json(\n                                exclude={\"streams\": {\"__all__\": \"frames\"}}\n                            ).encode(\"utf8\")\n                        ]\n                        + message.get_all_frames()\n                    )\n                    self._logger.debug(\"sent message to worker %s\", worker)\n        except asyncio.exceptions.CancelledError:\n            self._logger.info(\"stopping worker\")\n            if self.dump_file:\n                self._logger.info(\n                    \"closing dump file %s at cancelled work\", self.dump_file\n                )\n                self.dump_file.close()\n\n    async def run_source(self, stream: StreamName) -&gt; AsyncGenerator[StreamData, None]:\n        \"\"\"\n        This generator must be implemented by the customised subclass. It should return exactly one `StreamData` object\n        for every frame arriving from upstream.\n\n        Arguments:\n            stream: optionally it received a stream name for which is should yield frames.\n\n        Returns:\n            Yield a StreamData object for every received frame.\n        \"\"\"\n        yield StreamData(typ=\"\", frames=[])\n        return\n\n    async def accept_workers(self) -&gt; None:\n        \"\"\"\n        To allow zmq to learn the names of attached workers, they periodically send empty packets.\n        There is no information flow directly from workers to ingesters, so we discard the data.\n        \"\"\"\n        poller = zmq.asyncio.Poller()\n        poller.register(self.out_socket, zmq.POLLIN)\n        while True:\n            socks = dict(await poller.poll())\n            for sock in socks:\n                data = await sock.recv_multipart()\n                self._logger.debug(\"new worker connected %s\", data[0])\n\n    async def close(self) -&gt; None:\n        \"\"\"\n        Clean up any open connections\n        \"\"\"\n        self.accept_task.cancel()\n        self.work_task.cancel()\n        await self.redis.delete(RedisKeys.config(\"ingester\", self.state.name))\n        await super().close()\n        self.ctx.destroy(linger=0)\n        self._logger.info(\"closed ingester\")\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.accept_workers","title":"<code>accept_workers()</code>  <code>async</code>","text":"<p>To allow zmq to learn the names of attached workers, they periodically send empty packets. There is no information flow directly from workers to ingesters, so we discard the data.</p> Source code in <code>dranspose/ingester.py</code> <pre><code>async def accept_workers(self) -&gt; None:\n    \"\"\"\n    To allow zmq to learn the names of attached workers, they periodically send empty packets.\n    There is no information flow directly from workers to ingesters, so we discard the data.\n    \"\"\"\n    poller = zmq.asyncio.Poller()\n    poller.register(self.out_socket, zmq.POLLIN)\n    while True:\n        socks = dict(await poller.poll())\n        for sock in socks:\n            data = await sock.recv_multipart()\n            self._logger.debug(\"new worker connected %s\", data[0])\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.close","title":"<code>close()</code>  <code>async</code>","text":"<p>Clean up any open connections</p> Source code in <code>dranspose/ingester.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"\n    Clean up any open connections\n    \"\"\"\n    self.accept_task.cancel()\n    self.work_task.cancel()\n    await self.redis.delete(RedisKeys.config(\"ingester\", self.state.name))\n    await super().close()\n    self.ctx.destroy(linger=0)\n    self._logger.info(\"closed ingester\")\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.finish_work","title":"<code>finish_work()</code>  <code>async</code>","text":"<p>This hook is called when all events of a trigger map were ingested. It is useful for e.g. closing open files.</p> Source code in <code>dranspose/ingester.py</code> <pre><code>async def finish_work(self) -&gt; None:\n    \"\"\"\n    This hook is called when all events of a trigger map were ingested. It is useful for e.g. closing open files.\n    \"\"\"\n    self._logger.info(\"finishing work\")\n    if self.dump_file:\n        self.dump_file.close()\n        self._logger.info(\"closed dump file at finish %s\", self.dump_file)\n        self.dump_file = None\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.manage_assignments","title":"<code>manage_assignments()</code>  <code>async</code>","text":"<p>A background task reading assignments from the controller, filering them for the relevant ones and enqueueing them for when the frame arrives.</p> Source code in <code>dranspose/ingester.py</code> <pre><code>async def manage_assignments(self) -&gt; None:\n    \"\"\"\n    A background task reading assignments from the controller, filering them for the relevant ones and enqueueing them for when the frame arrives.\n    \"\"\"\n    self._logger.info(\"started ingester manage assign task\")\n    lastev = 0\n    while True:\n        sub = RedisKeys.assigned(self.state.mapping_uuid)\n        try:\n            assignments = await self.redis.xread({sub: lastev}, block=1000)\n        except rexceptions.ConnectionError:\n            break\n        if sub not in assignments:\n            continue\n        assignment_evs = assignments[sub][0]\n        self._logger.debug(\"got assignments %s\", assignment_evs)\n        for assignment in assignment_evs:\n            wa = WorkAssignment.model_validate_json(assignment[1][\"data\"])\n            mywa = wa.get_workers_for_streams(self.state.streams)\n            await self.assignment_queue.put(mywa)\n            lastev = assignment[0]\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.restart_work","title":"<code>restart_work(new_uuid)</code>  <code>async</code>","text":"<p>Restarts all work related tasks to make sure no old state is present in a new scan.</p> <p>Parameters:</p> Name Type Description Default <code>new_uuid</code> <code>UUID4</code> <p>The uuid of the new mapping</p> required Source code in <code>dranspose/ingester.py</code> <pre><code>async def restart_work(self, new_uuid: UUID4) -&gt; None:\n    \"\"\"\n    Restarts all work related tasks to make sure no old state is present in a new scan.\n\n    Arguments:\n        new_uuid: The uuid of the new mapping\n    \"\"\"\n    self.work_task.cancel()\n    self.assign_task.cancel()\n    self.state.mapping_uuid = new_uuid\n    self.assignment_queue = asyncio.Queue()\n    self.work_task = asyncio.create_task(self.work())\n    self.assign_task = asyncio.create_task(self.manage_assignments())\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Main function orchestrating the dependent tasks. This needs to be called from an async context once an instance is created.</p> Source code in <code>dranspose/ingester.py</code> <pre><code>async def run(self) -&gt; None:\n    \"\"\"\n    Main function orchestrating the dependent tasks. This needs to be called from an async context once an instance is created.\n    \"\"\"\n    self.accept_task = asyncio.create_task(self.accept_workers())\n    self.work_task = asyncio.create_task(self.work())\n    self.assign_task = asyncio.create_task(self.manage_assignments())\n    self.assignment_queue: asyncio.Queue[WorkAssignment] = asyncio.Queue()\n    await self.register()\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.run_source","title":"<code>run_source(stream)</code>  <code>async</code>","text":"<p>This generator must be implemented by the customised subclass. It should return exactly one <code>StreamData</code> object for every frame arriving from upstream.</p> <p>Parameters:</p> Name Type Description Default <code>stream</code> <code>StreamName</code> <p>optionally it received a stream name for which is should yield frames.</p> required <p>Returns:</p> Type Description <code>AsyncGenerator[StreamData, None]</code> <p>Yield a StreamData object for every received frame.</p> Source code in <code>dranspose/ingester.py</code> <pre><code>async def run_source(self, stream: StreamName) -&gt; AsyncGenerator[StreamData, None]:\n    \"\"\"\n    This generator must be implemented by the customised subclass. It should return exactly one `StreamData` object\n    for every frame arriving from upstream.\n\n    Arguments:\n        stream: optionally it received a stream name for which is should yield frames.\n\n    Returns:\n        Yield a StreamData object for every received frame.\n    \"\"\"\n    yield StreamData(typ=\"\", frames=[])\n    return\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.work","title":"<code>work()</code>  <code>async</code>","text":"<p>The heavy liftig function of an ingester. It consumes a generator <code>run_source()</code> which should be implemented for a specific protocol. It then assembles all streams for this ingester and forwards them to the assigned workers.</p> <p>Optionally the worker dumps the internal messages to disk. This is useful to develop workers with actual data captured.</p> Source code in <code>dranspose/ingester.py</code> <pre><code>async def work(self) -&gt; None:\n    \"\"\"\n    The heavy liftig function of an ingester. It consumes a generator `run_source()` which\n    should be implemented for a specific protocol.\n    It then assembles all streams for this ingester and forwards them to the assigned workers.\n\n    Optionally the worker dumps the internal messages to disk. This is useful to develop workers with actual data captured.\n    \"\"\"\n    self._logger.info(\"started ingester work task\")\n    sourcegens = {stream: self.run_source(stream) for stream in self.state.streams}\n    self.dump_file = None\n    if self._ingester_settings.dump_path:\n        self.dump_file = open(self._ingester_settings.dump_path, \"ab\")\n        self._logger.info(\n            \"dump file %s opened at %s\",\n            self._ingester_settings.dump_path,\n            self.dump_file,\n        )\n    try:\n        while True:\n            work_assignment: WorkAssignment = await self.assignment_queue.get()\n            workermessages = {}\n            zmqyields: list[Awaitable[StreamData]] = []\n            streams: list[StreamName] = []\n            for stream in work_assignment.assignments:\n                zmqyields.append(anext(sourcegens[stream]))\n                streams.append(stream)\n            zmqstreams: list[StreamData] = await asyncio.gather(*zmqyields)\n            zmqparts: dict[StreamName, StreamData] = {\n                stream: zmqpart for stream, zmqpart in zip(streams, zmqstreams)\n            }\n            if self.dump_file:\n                self._logger.debug(\n                    \"writing dump to path %s\", self._ingester_settings.dump_path\n                )\n                allstr = InternalWorkerMessage(\n                    event_number=work_assignment.event_number,\n                    streams={k: v.get_bytes() for k, v in zmqparts.items()},\n                )\n                try:\n                    pickle.dump(allstr, self.dump_file)\n                except Exception as e:\n                    self._logger.error(\"cound not dump %s\", e.__repr__())\n                self._logger.debug(\"written dump\")\n            for stream, workers in work_assignment.assignments.items():\n                for worker in workers:\n                    if worker not in workermessages:\n                        workermessages[worker] = InternalWorkerMessage(\n                            event_number=work_assignment.event_number\n                        )\n                    workermessages[worker].streams[stream] = zmqparts[stream]\n            self._logger.debug(\"workermessages %s\", workermessages)\n            for worker, message in workermessages.items():\n                self._logger.debug(\n                    \"header is %s\",\n                    message.model_dump_json(\n                        exclude={\"streams\": {\"__all__\": \"frames\"}}\n                    ),\n                )\n                await self.out_socket.send_multipart(\n                    [worker.encode(\"ascii\")]\n                    + [\n                        message.model_dump_json(\n                            exclude={\"streams\": {\"__all__\": \"frames\"}}\n                        ).encode(\"utf8\")\n                    ]\n                    + message.get_all_frames()\n                )\n                self._logger.debug(\"sent message to worker %s\", worker)\n    except asyncio.exceptions.CancelledError:\n        self._logger.info(\"stopping worker\")\n        if self.dump_file:\n            self._logger.info(\n                \"closing dump file %s at cancelled work\", self.dump_file\n            )\n            self.dump_file.close()\n</code></pre>"},{"location":"reference/protocols/events/","title":"Events","text":""},{"location":"reference/protocols/events/#dranspose.event.EventData","title":"<code>EventData</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Main container for an event provided to the worker function</p> <p>Attributes:</p> Name Type Description <code>event_number</code> <code>EventNumber</code> <p>Current event number relative to the trigger map provided</p> <code>streams</code> <code>dict[StreamName, StreamData]</code> <p>Data for each stream present in the event</p> Source code in <code>dranspose/event.py</code> <pre><code>class EventData(BaseModel):\n    \"\"\"\n    Main container for an event provided to the worker function\n\n    Attributes:\n        event_number:    Current event number relative to the trigger map provided\n        streams:         Data for each stream present in the event\n    \"\"\"\n\n    event_number: EventNumber\n    streams: dict[StreamName, StreamData]\n\n    @classmethod\n    def from_internals(cls, msgs: list[InternalWorkerMessage]) -&gt; \"EventData\":\n        \"\"\"\n        Helper function to assemble an event from the internal messages received from the ingesters.\n        This is a factory method\n\n        Args:\n             msgs: Internal messages each containing a subset of the streams for the event\n\n        Returns:\n            A new object with all data combined.\n        \"\"\"\n        assert len(msgs) &gt; 0, \"merge at least one message\"\n        assert (\n            len(set([m.event_number for m in msgs])) == 1\n        ), \"Cannot merge data from different events\"\n        all_stream_names = [stream for m in msgs for stream in m.streams.keys()]\n        assert len(all_stream_names) == len(\n            set(all_stream_names)\n        ), \"Cannot merge data with duplicate streams\"\n\n        ret = EventData(event_number=msgs[0].event_number, streams={})\n        for msg in msgs:\n            ret.streams.update(msg.streams)\n        return ret\n</code></pre>"},{"location":"reference/protocols/events/#dranspose.event.EventData.from_internals","title":"<code>from_internals(msgs)</code>  <code>classmethod</code>","text":"<p>Helper function to assemble an event from the internal messages received from the ingesters. This is a factory method</p> <p>Parameters:</p> Name Type Description Default <code>msgs</code> <code>list[InternalWorkerMessage]</code> <p>Internal messages each containing a subset of the streams for the event</p> required <p>Returns:</p> Type Description <code>EventData</code> <p>A new object with all data combined.</p> Source code in <code>dranspose/event.py</code> <pre><code>@classmethod\ndef from_internals(cls, msgs: list[InternalWorkerMessage]) -&gt; \"EventData\":\n    \"\"\"\n    Helper function to assemble an event from the internal messages received from the ingesters.\n    This is a factory method\n\n    Args:\n         msgs: Internal messages each containing a subset of the streams for the event\n\n    Returns:\n        A new object with all data combined.\n    \"\"\"\n    assert len(msgs) &gt; 0, \"merge at least one message\"\n    assert (\n        len(set([m.event_number for m in msgs])) == 1\n    ), \"Cannot merge data from different events\"\n    all_stream_names = [stream for m in msgs for stream in m.streams.keys()]\n    assert len(all_stream_names) == len(\n        set(all_stream_names)\n    ), \"Cannot merge data with duplicate streams\"\n\n    ret = EventData(event_number=msgs[0].event_number, streams={})\n    for msg in msgs:\n        ret.streams.update(msg.streams)\n    return ret\n</code></pre>"},{"location":"reference/protocols/events/#dranspose.event.InternalWorkerMessage","title":"<code>InternalWorkerMessage</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>A container for partial events which carries one or more streams. This is the message between ingesters and workers.</p> <p>Attributes:</p> Name Type Description <code>event_number</code> <code>EventNumber</code> <p>event number</p> <code>streams</code> <code>dict[StreamName, StreamData]</code> <p>one or more streams from an ingester</p> Source code in <code>dranspose/event.py</code> <pre><code>class InternalWorkerMessage(BaseModel):\n    \"\"\"\n    A container for partial events which carries one or more streams. This is the message between ingesters and workers.\n\n    Attributes:\n        event_number: event number\n        streams: one or more streams from an ingester\n    \"\"\"\n\n    event_number: EventNumber\n    streams: dict[StreamName, StreamData] = {}\n\n    def get_all_frames(self) -&gt; list[zmq.Frame | bytes]:\n        return [frame for stream in self.streams.values() for frame in stream.frames]\n</code></pre>"},{"location":"reference/protocols/events/#dranspose.event.ResultData","title":"<code>ResultData</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Container for transferring results from the worker to the reducer. In enhances the pure payload with useful meta data</p> <p>Attributes:</p> Name Type Description <code>event_number</code> <code>EventNumber</code> <p>which event the result belongs to. NB: results may arrive out of order</p> <code>worker</code> <code>WorkerName</code> <p>which worker processed it.</p> <code>parameters_uuid</code> <code>Optional[UUID4]</code> <p>which version of parameters was used to process the event</p> <code>payload</code> <code>Any</code> <p>the data return from the custom worker function: process_event</p> Source code in <code>dranspose/event.py</code> <pre><code>class ResultData(BaseModel):\n    \"\"\"\n    Container for transferring results from the worker to the reducer. In enhances the pure payload with useful meta data\n\n    Attributes:\n        event_number: which event the result belongs to. NB: results may arrive out of order\n        worker: which worker processed it.\n        parameters_uuid: which version of parameters was used to process the event\n        payload: the data return from the custom worker function: process_event\n    \"\"\"\n\n    event_number: EventNumber\n    worker: WorkerName\n    parameters_uuid: Optional[UUID4]\n    payload: Any\n</code></pre>"},{"location":"reference/protocols/events/#dranspose.event.StreamData","title":"<code>StreamData</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Data container for a single stream with all zmq frames belonging to it</p> <p>Attributes:</p> Name Type Description <code>typ</code> <code>str</code> <p>arbitrary typ set by the ingester to common parsing</p> <code>frames</code> <code>list[Frame] | list[bytes]</code> <p>all frames received for this event for the stream</p> Source code in <code>dranspose/event.py</code> <pre><code>class StreamData(BaseModel):\n    \"\"\"\n    Data container for a single stream with all zmq frames belonging to it\n\n    Attributes:\n         typ: arbitrary typ set by the ingester to common parsing\n         frames: all frames received for this event for the stream\n    \"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    typ: str\n    frames: list[zmq.Frame] | list[bytes]\n\n    @computed_field\n    @property\n    def length(self) -&gt; int:\n        \"\"\"\n        Calculates the length of frames.\n\n        Returns:\n             length of frames\n        \"\"\"\n        return len(self.frames)\n\n    def get_bytes(self) -&gt; \"StreamData\":\n        \"\"\"\n        Copies the data from the zmq buffer\n\n        Returns:\n             An object with a list of bytes.\n        \"\"\"\n        return StreamData(\n            typ=self.typ,\n            frames=[\n                frame.bytes if isinstance(frame, zmq.Frame) else frame\n                for frame in self.frames\n            ],\n        )\n</code></pre>"},{"location":"reference/protocols/events/#dranspose.event.StreamData.length","title":"<code>length: int</code>  <code>property</code>","text":"<p>Calculates the length of frames.</p> <p>Returns:</p> Type Description <code>int</code> <p>length of frames</p>"},{"location":"reference/protocols/events/#dranspose.event.StreamData.get_bytes","title":"<code>get_bytes()</code>","text":"<p>Copies the data from the zmq buffer</p> <p>Returns:</p> Type Description <code>StreamData</code> <p>An object with a list of bytes.</p> Source code in <code>dranspose/event.py</code> <pre><code>def get_bytes(self) -&gt; \"StreamData\":\n    \"\"\"\n    Copies the data from the zmq buffer\n\n    Returns:\n         An object with a list of bytes.\n    \"\"\"\n    return StreamData(\n        typ=self.typ,\n        frames=[\n            frame.bytes if isinstance(frame, zmq.Frame) else frame\n            for frame in self.frames\n        ],\n    )\n</code></pre>"},{"location":"tutorials/ingesters/","title":"Ingesters","text":"<p>Writing new ingesters is required for consuming new data streams.</p>"}]}